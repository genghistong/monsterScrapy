from scrapy.spider import Spider
from scrapy.selector import Selector

from monster.items import MonsterItem


class DiceSpider(Spider):
    name = "dice"
    allowed_domains = ["dice.com"]
    start_urls = [
        "https://www.dice.com/jobs/q-information+technology-sort-date-jobs.html",
        "http://jobs.monster.com/v-technology.aspx?page=2",
        "http://jobs.monster.com/v-technology.aspx?page=3",
        "http://jobs.monster.com/v-technology.aspx?page=4",
        "http://jobs.monster.com/v-technology.aspx?page=5",
        "http://jobs.monster.com/v-technology.aspx?page=6",
        "http://jobs.monster.com/v-technology.aspx?page=7",
        "http://jobs.monster.com/v-technology.aspx?page=8",
        "http://jobs.monster.com/v-technology.aspx?page=9",
        "http://jobs.monster.com/v-technology.aspx?page=10",
        "http://jobs.monster.com/v-technology.aspx?page=11",
        "http://jobs.monster.com/v-technology.aspx?page=12",
        "http://jobs.monster.com/v-technology.aspx?page=13",
        "http://jobs.monster.com/v-technology.aspx?page=14",
        "http://jobs.monster.com/v-technology.aspx?page=15",
        "http://jobs.monster.com/v-technology.aspx?page=16",
        "http://jobs.monster.com/v-technology.aspx?page=17",
        "http://jobs.monster.com/v-technology.aspx?page=18",
        "http://jobs.monster.com/v-technology.aspx?page=19"

    ]

    def parse(self, response):
        sel = Selector(response)
        sites = sel.xpath('//div[@id="serp"]')
        items = []

        for site in sites.select('..//div[@class="serp-result-content"]'):
            item = MonsterItem()
            item['title'] = site.xpath('.//a[@class = "dice-btn-link"]/text()').extract()
            item['company'] = site.xpath('.//li[@class = "employer"]/text()').extract()
            item['city'] = str(site.xpath('.//li[@class = "location"]/text()').extract()).split(',')[0] + "']"
            item['state'] = "['" + str(site.xpath('.//li[@class = "location"]/text()').extract()).split(', ')[1]
            item['description'] = site.xpath('.//div[@class = "shortdesc"]/text()').extract()
            if item not in items:
                items.append(item)
            #limiting it to 100 does not work, maybe because it's counting
            #the length of the site loop which never exceeds 20?
            #if len(items) > 100:
            #    break
        return items
